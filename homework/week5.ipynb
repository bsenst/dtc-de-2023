{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/cohorts/2023/week_5_batch_processing/homework.md\n# https://github.com/jkthompson/pyspark-pictures\n\n! pip install pyspark","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-25T10:06:32.905959Z","iopub.execute_input":"2023-02-25T10:06:32.906424Z","iopub.status.idle":"2023-02-25T10:07:41.092781Z","shell.execute_reply.started":"2023-02-25T10:06:32.906381Z","shell.execute_reply":"2023-02-25T10:07:41.091467Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting py4j==0.10.9.5\n  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=ae39734fd853efe72aa3f05473936e52fc75ed918d3a5d51ac8284e486350a12\n  Stored in directory: /root/.cache/pip/wheels/5a/54/9b/a89cac960efb57c4c35d41cc7c9f7b80daa21108bc376339b7\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\n  Attempting uninstall: py4j\n    Found existing installation: py4j 0.10.9.7\n    Uninstalling py4j-0.10.9.7:\n      Successfully uninstalled py4j-0.10.9.7\nSuccessfully installed py4j-0.10.9.5 pyspark-3.3.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName(\"dtc-de-2023-nyc-taxi\").getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2023-02-25T10:07:41.095296Z","iopub.execute_input":"2023-02-25T10:07:41.095702Z","iopub.status.idle":"2023-02-25T10:07:46.752820Z","shell.execute_reply.started":"2023-02-25T10:07:41.095660Z","shell.execute_reply":"2023-02-25T10:07:46.751637Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","output_type":"stream"},{"name":"stdout","text":"23/02/25 10:07:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}]},{"cell_type":"code","source":"# Question 1:\nspark.version","metadata":{"execution":{"iopub.status.busy":"2023-02-25T10:07:46.754479Z","iopub.execute_input":"2023-02-25T10:07:46.755572Z","iopub.status.idle":"2023-02-25T10:07:46.764413Z","shell.execute_reply.started":"2023-02-25T10:07:46.755524Z","shell.execute_reply":"2023-02-25T10:07:46.763336Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'3.3.2'"},"metadata":{}}]},{"cell_type":"code","source":"! wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz","metadata":{"execution":{"iopub.status.busy":"2023-02-25T10:07:46.767421Z","iopub.execute_input":"2023-02-25T10:07:46.767862Z","iopub.status.idle":"2023-02-25T10:08:07.452868Z","shell.execute_reply.started":"2023-02-25T10:07:46.767820Z","shell.execute_reply":"2023-02-25T10:08:07.451664Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"--2023-02-25 10:07:47--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz\nResolving github.com (github.com)... 140.82.112.4\nConnecting to github.com (github.com)|140.82.112.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/4564ad9e-a6da-4923-ad6f-35ff02446a51?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230225%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230225T100748Z&X-Amz-Expires=300&X-Amz-Signature=941721897c4caf5e0dc518a12578cfca67a40d991f4b6cfdf3fe47de084352c7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-06.csv.gz&response-content-type=application%2Foctet-stream [following]\n--2023-02-25 10:07:48--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/4564ad9e-a6da-4923-ad6f-35ff02446a51?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230225%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230225T100748Z&X-Amz-Expires=300&X-Amz-Signature=941721897c4caf5e0dc518a12578cfca67a40d991f4b6cfdf3fe47de084352c7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-06.csv.gz&response-content-type=application%2Foctet-stream\nResolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 175799316 (168M) [application/octet-stream]\nSaving to: ‘fhvhv_tripdata_2021-06.csv.gz’\n\nfhvhv_tripdata_2021 100%[===================>] 167.66M  8.90MB/s    in 17s     \n\n2023-02-25 10:08:06 (9.63 MB/s) - ‘fhvhv_tripdata_2021-06.csv.gz’ saved [175799316/175799316]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"df = spark.read.option(\"header\", \"true\").csv(\"/kaggle/working/fhvhv_tripdata_2021-06.csv.gz\")\ndf.printSchema()","metadata":{"execution":{"iopub.status.busy":"2023-02-25T10:08:07.454922Z","iopub.execute_input":"2023-02-25T10:08:07.455400Z","iopub.status.idle":"2023-02-25T10:08:14.228579Z","shell.execute_reply.started":"2023-02-25T10:08:07.455356Z","shell.execute_reply":"2023-02-25T10:08:14.227293Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"root\n |-- dispatching_base_num: string (nullable = true)\n |-- pickup_datetime: string (nullable = true)\n |-- dropoff_datetime: string (nullable = true)\n |-- PULocationID: string (nullable = true)\n |-- DOLocationID: string (nullable = true)\n |-- SR_Flag: string (nullable = true)\n |-- Affiliated_base_number: string (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"df.rdd.getNumPartitions()","metadata":{"execution":{"iopub.status.busy":"2023-02-25T10:08:28.636084Z","iopub.execute_input":"2023-02-25T10:08:28.637094Z","iopub.status.idle":"2023-02-25T10:08:28.721238Z","shell.execute_reply.started":"2023-02-25T10:08:28.637038Z","shell.execute_reply":"2023-02-25T10:08:28.720338Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"# Question 2:\n# Repartition it to 12 partitions and save it to parquet.\ndf_12part = df.repartition(12)\ndf_12part.rdd.getNumPartitions()","metadata":{"execution":{"iopub.status.busy":"2023-02-25T10:08:32.029304Z","iopub.execute_input":"2023-02-25T10:08:32.029977Z","iopub.status.idle":"2023-02-25T10:09:47.343951Z","shell.execute_reply.started":"2023-02-25T10:08:32.029934Z","shell.execute_reply":"2023-02-25T10:09:47.342525Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"[Stage 1:>                                                          (0 + 1) / 1]\r","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"12"},"metadata":{}}]},{"cell_type":"code","source":"# df_12part.write.parquet(\"df_12part.parquet\")","metadata":{"execution":{"iopub.status.busy":"2023-02-25T10:06:23.018578Z","iopub.status.idle":"2023-02-25T10:06:23.020812Z","shell.execute_reply.started":"2023-02-25T10:06:23.020452Z","shell.execute_reply":"2023-02-25T10:06:23.020492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder = \"/kaggle/working/df_12part.parquet/\"\n\nfile_sizes = 0\nparquet_file_count = 0\nfor file in os.listdir(folder):\n    if file.endswith(\"parquet\"):\n        file_size = os.path.getsize(folder+file)\n        print(str(file_size).ljust(10), file)\n        file_sizes += file_size\n        parquet_file_count += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)?\nprint(\"avg parquet file size\", file_sizes/parquet_file_count)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Question 3:\n# Count records\n# How many taxi trips were there on June 15?\n# Consider only trips that started on June 15.\ndf_12part = spark.read.parquet('/kaggle/working/df_12part.parquet')","metadata":{"execution":{"iopub.status.busy":"2023-02-24T21:31:58.380924Z","iopub.execute_input":"2023-02-24T21:31:58.381924Z","iopub.status.idle":"2023-02-24T21:32:04.011769Z","shell.execute_reply.started":"2023-02-24T21:31:58.381874Z","shell.execute_reply":"2023-02-24T21:32:04.010449Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"df_12part.rdd.first()","metadata":{"execution":{"iopub.status.busy":"2023-02-24T21:34:35.970259Z","iopub.execute_input":"2023-02-24T21:34:35.971466Z","iopub.status.idle":"2023-02-24T21:34:37.383053Z","shell.execute_reply.started":"2023-02-24T21:34:35.971410Z","shell.execute_reply":"2023-02-24T21:34:37.381803Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Row(dispatching_base_num='B02872', pickup_datetime='2021-06-12 21:48:21', dropoff_datetime='2021-06-12 22:01:16', PULocationID='125', DOLocationID='148', SR_Flag='N', Affiliated_base_number='B02872')"},"metadata":{}}]},{"cell_type":"code","source":"import pyspark.sql.functions as func\n\ndf = df_12part.select(func.to_date(df_12part.pickup_datetime).alias(\"time\"))\nsf = df.filter(df.time == \"2021-06-15\")\nsf.count()","metadata":{"execution":{"iopub.status.busy":"2023-02-25T10:16:49.044209Z","iopub.execute_input":"2023-02-25T10:16:49.044640Z","iopub.status.idle":"2023-02-25T10:17:14.801905Z","shell.execute_reply.started":"2023-02-25T10:16:49.044601Z","shell.execute_reply":"2023-02-25T10:17:14.800597Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"452470"},"metadata":{}}]},{"cell_type":"code","source":"# Question 4:\n# Longest trip for each day\n# Now calculate the duration for each trip.\n# How long was the longest trip in Hours?\n\ndf = df_12part.withColumn('trip_duration',\n                     (func.unix_timestamp(df_12part.dropoff_datetime) - func.unix_timestamp(df_12part.pickup_datetime)))\n\ndf.show(5)","metadata":{"execution":{"iopub.status.busy":"2023-02-25T10:29:22.700521Z","iopub.execute_input":"2023-02-25T10:29:22.701169Z","iopub.status.idle":"2023-02-25T10:30:47.528452Z","shell.execute_reply.started":"2023-02-25T10:29:22.701102Z","shell.execute_reply":"2023-02-25T10:30:47.526880Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"[Stage 29:>                                                         (0 + 1) / 1]\r","output_type":"stream"},{"name":"stdout","text":"+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-------------+\n|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|trip_duration|\n+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-------------+\n|              B02682|2021-06-03 21:14:32|2021-06-03 21:25:50|         231|         114|      N|                B02682|          678|\n|              B02880|2021-06-23 17:40:44|2021-06-23 18:04:19|          41|         163|      N|                B02880|         1415|\n|              B02510|2021-06-06 02:07:03|2021-06-06 02:24:30|          75|         250|      N|                  null|         1047|\n|              B02865|2021-06-06 04:48:19|2021-06-06 05:15:14|         158|          22|      N|                B02865|         1615|\n|              B02872|2021-06-16 15:31:51|2021-06-16 16:18:09|          90|          56|      N|                B02872|         2778|\n+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-------------+\nonly showing top 5 rows\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"df.agg({'trip_duration': 'max'}).show(5)","metadata":{"execution":{"iopub.status.busy":"2023-02-25T10:31:38.888783Z","iopub.execute_input":"2023-02-25T10:31:38.890213Z","iopub.status.idle":"2023-02-25T10:32:58.436500Z","shell.execute_reply.started":"2023-02-25T10:31:38.890141Z","shell.execute_reply":"2023-02-25T10:32:58.434973Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"[Stage 34:==========================================>              (9 + 3) / 12]\r","output_type":"stream"},{"name":"stdout","text":"+------------------+\n|max(trip_duration)|\n+------------------+\n|            240764|\n+------------------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"240764 / 60 / 60","metadata":{"execution":{"iopub.status.busy":"2023-02-25T10:33:12.623843Z","iopub.execute_input":"2023-02-25T10:33:12.624280Z","iopub.status.idle":"2023-02-25T10:33:12.632672Z","shell.execute_reply.started":"2023-02-25T10:33:12.624229Z","shell.execute_reply":"2023-02-25T10:33:12.631219Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"66.87888888888888"},"metadata":{}}]},{"cell_type":"code","source":"# Question 5:\n# User Interface\n# Spark’s User Interface which shows application's dashboard runs on which local port?\n4040","metadata":{"execution":{"iopub.status.busy":"2023-02-24T21:58:08.719622Z","iopub.execute_input":"2023-02-24T21:58:08.720860Z","iopub.status.idle":"2023-02-24T21:58:08.729109Z","shell.execute_reply.started":"2023-02-24T21:58:08.720793Z","shell.execute_reply":"2023-02-24T21:58:08.727783Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"4040"},"metadata":{}}]},{"cell_type":"code","source":"# Question 6:\n# Most frequent pickup location zone\n# Load the zone lookup data into a temp view in Spark\n# https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n# Using the zone lookup data and the fhvhv June 2021 data, what is the name of the most frequent pickup location zone?\n# East Chelsea\n# Astoria\n# Union Sq\n# Crown Heights North\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-24T22:10:39.161531Z","iopub.execute_input":"2023-02-24T22:10:39.162042Z","iopub.status.idle":"2023-02-24T22:10:39.168071Z","shell.execute_reply.started":"2023-02-24T22:10:39.161983Z","shell.execute_reply":"2023-02-24T22:10:39.166505Z"},"trusted":true},"execution_count":25,"outputs":[]}]}